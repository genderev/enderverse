<html>

<head>
  <meta charset='UTF-8'>
  <title>action painting</title>
  <link rel='stylesheet' type='text/css' href='../css/latex.css'>
  <meta name='viewport' content='width=device-width, initial-scale=1.0'>
  <meta name='author' content='Ender Minyard'>

</head>

<body>
  <h1>action painting</h1>
  <canvas id='canvas' width='640' height='480'></canvas>
  <video id='video' width='640' height='480' autoplay style='display: none'></video>
  <canvas id='drawing' width='640' height='480'></canvas>
<script src='https://unpkg.com/ml5@latest/dist/ml5.min.js'></script>
  <script>
  var video = document.getElementById('video');
  var canvas = document.getElementById('canvas');
  var ctx = canvas.getContext('2d');


  let canv =  document.getElementById('drawing');
  let context = canv.getContext('2d')


  // The detected positions will be inside an array
  let poses = [];

  // Create a webcam capture
  if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
    navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {
      video.srcObject = stream;
      video.play();
    });
  }

  // A function to draw the video and poses into the canvas.
  // This function is independent of the result of posenet
  // This way the video will not seem slow if poseNet
  // is not detecting a position
  function drawCameraIntoCanvas() {
    // Draw the video element into the canvas
    ctx.drawImage(video, 0, 0, 640, 480);
    // We can call both functions to draw all keypoints and the skeletons
    drawAction();
    drawKeypoints();
    drawSkeleton();
    window.requestAnimationFrame(drawCameraIntoCanvas);
  }
  // Loop over the drawCameraIntoCanvas function
  drawCameraIntoCanvas();

  // Create a new poseNet method with a single detection
  const poseNet = ml5.poseNet(video, modelReady);
  poseNet.on('pose', gotPoses);

  // A function that gets called every time there's an update from the model
  function gotPoses(results) {
    poses = results;
  }

  function modelReady() {
    console.log('model ready');
    poseNet.multiPose(video);
  }

  function drawAction() {
    for (let i = 0; i < poses.length; i += 1) {
      context.beginPath();
      // For each pose detected, loop through all the keypoints
      for (let j = 0; j < poses[i].pose.keypoints.length; j += 1) {
        let keypoint = poses[i].pose.keypoints[j];
        // Only draw an ellipse is the pose probability is bigger than 0.2
        if (keypoint.score > 0.2) {
          context.lineTo(keypoint.position.x, keypoint.position.y);
          context.stroke();
        }
      }
      console.log(poses)
    }
  }

  // A function to draw ellipses over the detected keypoints
  function drawKeypoints() {
    // Loop through all the poses detected
    for (let i = 0; i < poses.length; i += 1) {
      // For each pose detected, loop through all the keypoints
      for (let j = 0; j < poses[i].pose.keypoints.length; j += 1) {
        let keypoint = poses[i].pose.keypoints[j];
        // Only draw an ellipse is the pose probability is bigger than 0.2
        if (keypoint.score > 0.2) {
          ctx.beginPath();
          ctx.arc(keypoint.position.x, keypoint.position.y, 10, 0, 2 * Math.PI);
          ctx.stroke();
        }
      }
    }

  }

  // A function to draw the skeletons
  function drawSkeleton() {
    // Loop through all the skeletons detected
    for (let i = 0; i < poses.length; i += 1) {
      // For every skeleton, loop through all body connections
      for (let j = 0; j < poses[i].skeleton.length; j += 1) {
        let partA = poses[i].skeleton[j][0];
        let partB = poses[i].skeleton[j][1];
        ctx.beginPath();
        ctx.moveTo(partA.position.x, partA.position.y);
        ctx.lineTo(partB.position.x, partB.position.y);
        ctx.stroke();
      }
    }
  }


  </script>
</body>

</html>
